# AI_Lab_Assignment
```
1.Name: Deuja Ritik
2.Student_ID: 12194824
3.Course: AI Application System
4.Course Code: ISE4132
```

# Course Objectives:
```
- Practice ROS/ROS2 python/C++ client library: Creating your own ROS/2 C++/Python programs
- Practice the recent simulating tool with ROS: RVIZ, RQT, Gazebo simulator
- Familiarize the student with the recent machine learning project with ROS/ROS2
- Familiarize the student with the recent Autonomous Vehicle project with ROS/ROS2
```

# Course Goals:

## 1.Week_3_lecture

*• To Get Started with Google Colab.*

*• To learn Basic data uploading at google colab.*

*• At last, Importing Kaggle’s dataset and operating Basic Files.*

https://github.com/deujahritik/AI__12194824/blob/main/intro_colab.ipynb

## 2.Week_4_lecture

*• To Introduce  Datasets used when training networks.*

*• To Extend the network and learn how algorithm  do multiclass classification.*

*• Use of Network for Digit Classification.*

*• Loss Function for Multiclass Classification.*

*• Programming Example: Classifying handwritten Digits.*

*• Mini-Batch gradient descent.*

 https://github.com/deujahritik/AI__12194824/blob/main/Google_colab.ipynb


## 3.Week_5_lecture

*• Meaning of Tensorflow which is w is a library based on Python that provides different types of functionality for deep learning models.*

*• Computational graph*

*• Variables, Constants and Placeholders in TensorFlow*

*• Tensorboard visualization*

*• `tf.summary.scalar` command*

*• `tf.summary.histogram` command*

https://github.com/deujahritik/AI__12194824/blob/main/tensorflow.ipynb
https://github.com/deujahritik/AI__12194824/blob/main/pip_installation.ipynb

## 3.Week_6_lecture

*• To learn Linear Regression using TensorFlow*

*• Visualization of Linear Regression parameters using TensorFlow*

*• Digit Classification | Neural network to classify MNIST dataset using TensorFlow*

https://github.com/deujahritik/AI__12194824/blob/main/week6_2.ipynb
https://github.com/deujahritik/AI__12194824/blob/main/Week_6__tensorflow_session2_.ipynb
https://github.com/deujahritik/AI__12194824/blob/main/Week6_Linear_Regression%202.ipynb
https://github.com/deujahritik/AI__12194824/blob/main/Week6_Linear_Regression%20(2).ipynb


## 4.Week_7_lecture
*• Pytorch: PyTorch is a system for executing dynamic computational graphs over Tensor objects that behave similarly as numpy ndarray. It comes with a powerful automatic differentiation engine that removes the need for manual back-propagation.*

*• Convolutional Neural Networks*

*• The CIFAR-10 Dataset*

*• Characteristics and building blocks for convolutional layers*

*• Combining feature maps into a convolutional layer*

*• Combining convolutional and fully connected layers into a network*

*• Effects of sparse connections and weight sharing*

*• Image classification with a convolutional network*

https://github.com/deujahritik/AI__12194824/blob/main/Week_7_lab_session-2.ipynb
https://github.com/deujahritik/AI__12194824/blob/main/Week_7_lab_session_CIFAR10_withTorch.ipynb

## 5.Week_9

*• Logistic unit for binary classification*

*• Softmax unit for multiclass classification*

*• Linear unit for regression*

*• The Boston Housing dataset*

*• Predicting house prices with a DNN*

*• Improving generalization with regularization*

*• Experiment: Deeper and regularized models for house price prediction*

*• Concluding remarks on output units and regression problems.*

https://github.com/deujahritik/AI__12194824/blob/main/Week_9_AI_lab.ipynb
https://github.com/deujahritik/AI__12194824/blob/main/Week_9_lab_session-2.ipynb

## 5.Week_10

*• VGGNet*

*• GoogLeNet and ResNet*

*• Transfer Learning*

*• Data Augmentation as a Regularization Technique*

*• Mistakes made by CNNs*

*• Reducing parameters with Depthwise Separable Convolution*

*• Striking the right network design balance with EfficientNet*

https://github.com/deujahritik/AI__12194824/blob/main/Week_10_lab_session_dog_image.ipynb

## 6.Week_11_lecture
 
*• Limitations of Feedforward Networks*

*• Recurrent Neural Networks*

*• Mathematical Representation of a Recurrent layer*

*• Combining layers into an RNN*

*• Alternative veiw of RNN and Unrolling in Time*

*• Backpropagation Through Time*

*• Programming Example: Forecasting book sales*

https://github.com/deujahritik/AI__12194824/blob/main/Week_11_lab_session.ipynb

## 7.Week_12_lecture

*• Keeping Gradients Healthy*

*• Introduction to LSTM*

*• Creating a network of LSTM cells*

*• Alternative view of LSTM*

https://github.com/deujahritik/AI__12194824/blob/main/Week_12_lab_GroupF.ipynb

## 8.Week_13_lecture

*• Encoding text*

*• Longer-term prediction and autoregressive models*

*• Beam Search*

*• Bidirectional RNNS*

*• Different combinations of input and output sequences*

https://github.com/deujahritik/12194824/blob/main/Week_13_Lab_GroupF.ipynb
```
Prof. Mehdi Pirahandeh
```
